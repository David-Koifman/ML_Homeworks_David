{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f02f93-52d6-43b6-8858-f783fa79cf72",
   "metadata": {},
   "source": [
    "**Задание 3**\n",
    "\n",
    "1 Построить более сложную модель с подбором гиперпараметров\n",
    "2 Произвести подбор гиперпараметров с scikit-learn методами (или optuna) на кросс-валидации \n",
    "3 Обучить модель с лучшими подобранными значениями гиперпараметров\n",
    "4 Произвести измерение качества на отложенной выборке с использованием ранее выбранной метрики \n",
    "5 Проинтерпретировать полученную модель\n",
    "6 Добиться воспроизводимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a07a7d01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip -q install kagglehub\n",
    "!pip -q install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256d870-82b1-4d1f-8b34-685f814bde14",
   "metadata": {},
   "source": [
    "Импорты необходимых библиотек и фиксирование seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40b01ef2-76f1-40b4-a79a-4c013f990a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import kagglehub\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e2b01-df36-448f-a85a-60ce95708bda",
   "metadata": {},
   "source": [
    "Загрузка набора данных о ценнах на недвижимость в Мумбаи с сайта https://www.kaggle.com ,проверка успешности скачивания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "162a43f5-0993-42d2-86cf-190302189c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"kevinnadar22/mumbai-house-price-data-70k-entries\"\n",
    "\n",
    "data_dir = kagglehub.dataset_download(DATASET_NAME)\n",
    "csv_path = next((os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".csv\")), None)\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085f97c-a4fd-48cc-8d2b-5c42f351cd29",
   "metadata": {},
   "source": [
    "Предобработка данных. Удаление дубликатов и логарифмирование целевой переменной. Это преобразование уменьшает влияние экстремально дорогих объектов и стабилизирует дисперсию - это помогает простым моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ae1377a-fe6d-4a00-81f2-b5eb6506d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df[\"log_price\"] = np.log1p(df[\"price\"])\n",
    "\n",
    "target = \"log_price\"\n",
    "features = [\n",
    "    \"area\",\n",
    "    \"bedroom_num\",\n",
    "    \"bathroom_num\",\n",
    "    \"balcony_num\",\n",
    "    \"age\",\n",
    "    \"total_floors\",\n",
    "    \"property_type\",\n",
    "    \"furnished\",\n",
    "    \"locality\",\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442452cc-ee2e-485a-8cb6-907d4898b393",
   "metadata": {},
   "source": [
    "Разбиваем на 80/20 набор данных и фиксируем random_state, смотрим размерность разбивки. Проверяем воспроизводимость разбивки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40865a6a-967b-436a-9795-86324d58eb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные воспроизводимы\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "assert (X_train.index == X_train2.index).all()\n",
    "assert (X_test.index == X_test2.index).all()\n",
    "print(\"Данные воспроизводимы\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652fc6e-27cd-4663-864a-aa058eeef76b",
   "metadata": {},
   "source": [
    "1 Было решено в качестве новой модели выбрать **CatBoost** (ансамбль градиентного бустинга над деревьями решений) т.к Это значительно более мощный класс моделей по сравнению с линейной регрессией, так как он способен обучать нелинейные зависимости и автоматически строить сложные решающие правила. \n",
    "\n",
    "2 Также **CatBoost** хорошо работает с категориальными признаками, в отличие от RandomForest или XGBoost, он не требует ручного кодирования OneHotEncoder, он использует собственный оптимизированный способ кодирования категориальных признаков.\n",
    "\n",
    "3 CatBoost устойчив к дисбалансу цен и шуму -это особенно важно т.к рынок недвижимости Мумбая содержит очень дорогие объекты.\n",
    "\n",
    "4 CatBoost позволяет встроенный перебор гиперпараметров с кросс-валидацией.\n",
    "\n",
    "5 CatBoost показывает хорошою производительность на табличных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67bb87fe-3907-41e9-834f-b75d93075f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_idx = [6, 7, 8]\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_features_idx)\n",
    "test_pool = Pool(X_test, y_test, cat_features=categorical_features_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b4613d-4e4b-4e1a-87f9-c2c025d29c2e",
   "metadata": {},
   "source": [
    "Указываем индексы категориальных признаков \n",
    "\n",
    "Pool - это специальный формат данных CatBoost который хранит и обрабатывает категориальные данные, а такаже содержит данные и целевую переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b53ba719-b37b-4d1c-a096-a18c4e89cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(\n",
    "    loss_function=\"RMSE\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"depth\": [6, 8],\n",
    "    \"learning_rate\": [0.03, 0.1],\n",
    "    \"iterations\": [400, 600],\n",
    "    \"l2_leaf_reg\": [3, 5],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c907fb-e652-4664-a2cb-e6206281bad8",
   "metadata": {},
   "source": [
    "CatBoost — это алгоритм градиентного бустинга который строит множество деревьев решений одно за другим и каждое новое дерево исправляет ошибки предыдущего. CatBoost в частности хорошо работает с категориальными признаками автоматически их кодируя, что делает модель точнее и устойчивее.\n",
    "\n",
    "Здесь мыс создаём модель CatBoostRegressor, оптимизированную под нашу основную метрику RMSE, фиксируем RANDOM_STATE, а также отключаем вывод подробных логов.\n",
    "\n",
    "Далее создаем пространство гиперпараметров, по которому CatBoost перебирает комбинации в ходе grid-search, каждый параметр влияет на сложность модели и её способность учиться.\n",
    "\n",
    "**depth: [6, 8]**\n",
    "\n",
    "Глубина деревьев в бустинге.\n",
    "\n",
    "Пробуем 2 варианта \n",
    "\n",
    "6 — умеренно сложная модель.\n",
    "8 — более мощная модель но не слишком тяжёлая.\n",
    "\n",
    "**learning_rate: [0.03, 0.1]**\n",
    "\n",
    "Темп обучения насколько сильно модель корректирует свои ошибки на каждом шаге.\n",
    "\n",
    "Меньший (0.03) - обучение более устойчивое меньше риск переобучения но нужно больше итераций.\n",
    "Больший (0.1) - модель учится быстрее но есть риск переобучения.\n",
    "\n",
    "Это 2 классических значения для CatBoost. Безопасный вариант и более агрессивный.\n",
    "\n",
    "**iterations: [400, 600]**\n",
    "\n",
    "Количество деревьев в ансамбле.\n",
    "\n",
    "Меньшие количество деревьев более быстрое обучение но есть риска что модел неодоучится\n",
    "\n",
    "Большие количество но дольше обучение\n",
    "\n",
    "Огромное количесто есть риск переобучения\n",
    "\n",
    "400-600 оптимальный вариант который дает точность и скорось обучения\n",
    "\n",
    "**l2_leaf_reg = [3, 5]**\n",
    "\n",
    "Регуляризация листьев дерева - контролирует переобучение.\n",
    "\n",
    "Слишком маленькая регуляризация есть риск переобучения на дорогих объектах.\n",
    "\n",
    "Слишком сильная регуляризация  модель может недоучится особенно на больших данных.\n",
    "\n",
    "Значения 3 и 5 рекомендуемые для крупных табличных данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48afba81-713f-4b28-aaaf-1df38a42be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.3008052486\n",
      "bestIteration = 399\n",
      "\n",
      "\n",
      "bestTest = 0.2795688946\n",
      "bestIteration = 399\n",
      "\n",
      "\n",
      "bestTest = 0.304529708\n",
      "bestIteration = 399\n",
      "\n",
      "\n",
      "bestTest = 0.2804949847\n",
      "bestIteration = 399\n",
      "\n",
      "\n",
      "bestTest = 0.2916451668\n",
      "bestIteration = 599\n",
      "\n",
      "\n",
      "bestTest = 0.2747811369\n",
      "bestIteration = 599\n",
      "\n",
      "\n",
      "bestTest = 0.2945013475\n",
      "bestIteration = 599\n",
      "\n",
      "\n",
      "bestTest = 0.2751231946\n",
      "bestIteration = 599\n",
      "\n",
      "\n",
      "bestTest = 0.295022262\n",
      "bestIteration = 399\n",
      "\n",
      "\n",
      "bestTest = 0.2741269163\n",
      "bestIteration = 399\n",
      "\n",
      "\n",
      "bestTest = 0.300125803\n",
      "bestIteration = 399\n",
      "\n",
      "\n",
      "bestTest = 0.2753910661\n",
      "bestIteration = 399\n",
      "\n",
      "\n",
      "bestTest = 0.2847601215\n",
      "bestIteration = 599\n",
      "\n",
      "\n",
      "bestTest = 0.2706263854\n",
      "bestIteration = 599\n",
      "\n",
      "\n",
      "bestTest = 0.2895809307\n",
      "bestIteration = 599\n",
      "\n",
      "\n",
      "bestTest = 0.2712506588\n",
      "bestIteration = 599\n",
      "\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.2960641496\n",
      "bestIteration = 595\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.2859425292\n",
      "bestIteration = 599\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.2765873982\n",
      "bestIteration = 599\n",
      "\n",
      "{'depth': 8, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 600}\n"
     ]
    }
   ],
   "source": [
    "grid_search_results = model.grid_search(\n",
    "    param_grid,\n",
    "    X=train_pool,\n",
    "    cv=3,\n",
    "    partition_random_seed=RANDOM_STATE,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best_params = grid_search_results[\"params\"]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b181d94-4ccd-499e-9257-1c6617328897",
   "metadata": {},
   "source": [
    "grid_search перебирает все комбинации гиперпараметров из param_grid, обучает модель на каждой из них с 3-кратной кросс-валидацией и выбирает тот вариант где ошибка RMSE минимальна. Потом через best_params возвращаем лучшие значения гиперпараметров.\n",
    "\n",
    "**{'depth': 8, 'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 600}** \n",
    "\n",
    "Лучший результат с минимальной RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539bd4eb-5178-4cff-9bf7-9a649591c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model\n",
    "best_model.fit(train_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6f62e-e163-470b-a2c6-c8a615cc74cd",
   "metadata": {},
   "source": [
    "Сохраняем лучшую модель и обучаем модель уже на всём тренировочном наборе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18bd24d-5a71-476e-a7da-fd3071154b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = best_model.predict(test_pool)\n",
    "\n",
    "rmse_log = mean_squared_error(y_test, y_pred_log) ** 0.5\n",
    "mae_log = mean_absolute_error(y_test, y_pred_log)\n",
    "r2_log = r2_score(y_test, y_pred_log)\n",
    "\n",
    "y_test_inr = np.expm1(y_test)\n",
    "y_pred_inr = np.expm1(y_pred_log)\n",
    "\n",
    "rmse_inr = mean_squared_error(y_test_inr, y_pred_inr) ** 0.5\n",
    "mae_inr = mean_absolute_error(y_test_inr, y_pred_inr)\n",
    "\n",
    "print(f\"Ошибка RMSE (в логарифмах): {rmse_log:.4f}\")\n",
    "print(f\"Средняя абсолютная ошибка MAE (в логарифмах): {mae_log:.4f}\")\n",
    "print(f\"Коэффициент детерминации R²: {r2_log:.4f}\")\n",
    "print(f\"Ошибка RMSE (в рупиях): {rmse_inr:,.0f} ₨\")\n",
    "print(f\"Средняя абсолютная ошибка MAE (в рупиях): {mae_inr:,.0f} ₨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d241f-845b-4924-b283-c9f079c9a4ea",
   "metadata": {},
   "source": [
    "Делаем предсказания на тестовых данных затем вычисляем 3 метркии RMSE, MAE и R² , чтобы оценить точность модели в логарифмическом пространстве, где она обучалась. Затем переводим реальные и предсказанные значения обратно в рупии (expm1), чтобы получить ошибки в обычных денежных единицах. Финальные метрки RMSE и MAE в рупиях показывают, насколько модель ошибается в абсолютных ценах, что важно для бизнес-интерпретации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f618e-ac1d-4e7f-b47e-51b73d0d5f9e",
   "metadata": {},
   "source": [
    "**Результаты**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
